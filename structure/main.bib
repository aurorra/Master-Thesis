% !TEX root = ../main.tex

@article{Reference1,
	Abstract = {We have developed an enhanced Littrow configuration extended cavity diode laser (ECDL) that can be tuned without changing the direction of the output beam. The output of a conventional Littrow ECDL is reflected from a plane mirror fixed parallel to the tuning diffraction grating. Using a free-space Michelson wavemeter to measure the laser wavelength, we can tune the laser over a range greater than 10 nm without any alteration of alignment.},
	Author = {C. J. Hawthorn and K. P. Weber and R. E. Scholten},
	Journal = {Review of Scientific Instruments},
	Month = {12},
	Number = {12},
	Numpages = {3},
	Pages = {4477--4479},
	Title = {Littrow Configuration Tunable External Cavity Diode Laser with Fixed Direction Output Beam},
	Volume = {72},
	Url = {http://link.aip.org/link/?RSI/72/4477/1},
	Year = {2001}}

@article{Reference3,
	Abstract = {Operating a laser diode in an extended cavity which provides frequency-selective feedback is a very effective method of reducing the laser's linewidth and improving its tunability. We have developed an extremely simple laser of this type, built from inexpensive commercial components with only a few minor modifications. A 780~nm laser built to this design has an output power of 80~mW, a linewidth of 350~kHz, and it has been continuously locked to a Doppler-free rubidium transition for several days.},
	Author = {A. S. Arnold and J. S. Wilson and M. G. Boshier and J. Smith},
	Journal = {Review of Scientific Instruments},
	Month = {3},
	Number = {3},
	Numpages = {4},
	Pages = {1236--1239},
	Title = {A Simple Extended-Cavity Diode Laser},
	Volume = {69},
	Url = {http://link.aip.org/link/?RSI/69/1236/1},
	Year = {1998}}

@article{Reference2,
	Abstract = {We present a review of the use of diode lasers in atomic physics with an extensive list of references. We discuss the relevant characteristics of diode lasers and explain how to purchase and use them. We also review the various techniques that have been used to control and narrow the spectral outputs of diode lasers. Finally we present a number of examples illustrating the use of diode lasers in atomic physics experiments. Review of Scientific Instruments is copyrighted by The American Institute of Physics.},
	Author = {Carl E. Wieman and Leo Hollberg},
	Journal = {Review of Scientific Instruments},
	Keywords = {Diode Laser},
	Month = {1},
	Number = {1},
	Numpages = {20},
	Pages = {1--20},
	Title = {Using Diode Lasers for Atomic Physics},
	Volume = {62},
	Url = {http://link.aip.org/link/?RSI/62/1/1},
	Year = {1991}}

	@article{oller_analyzing_2020,
		title = {Analyzing Reinforcement Learning Benchmarks with Random Weight Guessing},
		url = {http://arxiv.org/abs/2004.07707},
		abstract = {We propose a novel method for analyzing and visualizing the complexity of standard reinforcement learning ({RL}) benchmarks based on score distributions. A large number of policy networks are generated by randomly guessing their parameters, and then evaluated on the benchmark task; the study of their aggregated results provide insights into the benchmark complexity. Our method guarantees objectivity of evaluation by sidestepping learning altogether: the policy network parameters are generated using Random Weight Guessing ({RWG}), making our method agnostic to (i) the classic {RL} setup, (ii) any learning algorithm, and (iii) hyperparameter tuning. We show that this approach isolates the environment complexity, highlights specific types of challenges, and provides a proper foundation for the statistical analysis of the task's difficulty. We test our approach on a variety of classic control benchmarks from the {OpenAI} Gym, where we show that small untrained networks can provide a robust baseline for a variety of tasks. The networks generated often show good performance even without gradual learning, incidentally highlighting the triviality of a few popular benchmarks.},
		journaltitle = {{arXiv}:2004.07707 [cs, stat]},
		author = {Oller, Declan and Glasmachers, Tobias and Cuccu, Giuseppe},
		urldate = {2021-12-07},
		date = {2020-04-16},
		eprinttype = {arxiv},
		eprint = {2004.07707},
		keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
		file = {arXiv Fulltext PDF:/home/corina/Zotero/storage/WN7HBCQY/Oller et al. - 2020 - Analyzing Reinforcement Learning Benchmarks with R.pdf:application/pdf;arXiv.org Snapshot:/home/corina/Zotero/storage/X95525AX/2004.html:text/html},
	}

	@article{ha2017evolving,
	  title   = {Evolving Stable Strategies},
	  author  = {Ha, David},
	  journal = {blog.otoro.net},
	  year    = {2017},
	  url     = {https://blog.otoro.net/2017/11/12/evolving-stable-strategies/}
	}

	@article{ha2017visual,
	  title   = {A Visual Guide to Evolution Strategies},
	  author  = {Ha, David},
	  journal = {blog.otoro.net},
	  year    = {2017},
	  url     = {https://blog.otoro.net/2017/10/29/visual-evolution-strategies/}
	}

	@article{brockman2016openai,
	  title={Openai gym},
	  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	  journal={arXiv preprint arXiv:1606.01540},
	  year={2016}
	}

	@book{fischer2014,
  title={Lineare Algebra},
  author={Fischer, Gerd},
  year={2014},
  publisher={Springer}
	}

	@article{schmidhuber2001evaluating,
  title={Evaluating benchmark problems by random guessing},
  author={Schmidhuber, J{\"u}rgen and Hochreiter, Sepp and Bengio, Yoshua},
  journal={A Field Guide to Dynamical Recurrent Networks},
  pages={231--235},
  year={2001},
  publisher={Wiley-IEEE Press, Hoboken, NJ, USA}
}

@ARTICLE{6313077,
author={Barto, Andrew G. and Sutton, Richard S. and Anderson, Charles W.},
journal={IEEE Transactions on Systems, Man, and Cybernetics},
title={Neuronlike adaptive elements that can solve difficult learning control problems},
year={1983},
volume={SMC-13},
number={5},
pages={834-846},
doi={10.1109/TSMC.1983.6313077}
}

@inproceedings{NIPS1995_8f1d4362,
 author = {Sutton, Richard S},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Touretzky and M.C. Mozer and M. Hasselmo},
 pages = {},
 publisher = {MIT Press},
 title = {Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding},
 volume = {8},
 year = {1995}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{montague1999reinforcement,
  title={Reinforcement learning: an introduction, by Sutton, RS and Barto, AG},
  author={Montague, P Read},
  journal={Trends in cognitive sciences},
  volume={3},
  number={9},
  pages={360},
  year={1999},
  publisher={Elsevier}
}

@article{moore1990efficient,
  title={Efficient memory-based learning for robot control},
  author={Moore, Andrew William},
  year={1990},
  publisher={Citeseer}
}

@incollection{kober2010imitation,
  title={Imitation and reinforcement learning for motor primitives with perceptual coupling},
  author={Kober, Jens and Mohler, Betty and Peters, Jan},
  booktitle={From motor learning to interaction learning in robots},
  pages={209--225},
  year={2010},
  publisher={Springer}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@ARTICLE{8103164,
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  title={Deep Reinforcement Learning: A Brief Survey},
  year={2017},
  volume={34},
  number={6},
  pages={26-38},
  doi={10.1109/MSP.2017.2743240}}

	@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{anderson2000approximating,
  title={Approximating a policy can be easier than approximating a value function},
  author={Anderson, Charles W},
  journal={Computer Science Technical Report},
  year={2000}
}

@article{franccois2018introduction,
  title={An introduction to deep reinforcement learning},
  author={Fran{\c{c}}ois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G and Pineau, Joelle and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={3-4},
  pages={219--354},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@article{such2017deep,
  title={Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning},
  author={Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1712.06567},
  year={2017}
}

@article{hansen2016cma,
  title={The CMA evolution strategy: A tutorial},
  author={Hansen, Nikolaus},
  journal={arXiv preprint arXiv:1604.00772},
  year={2016}
}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2016},
  organization={PMLR}
}

@article{DBLP:journals/corr/abs-1806-01363,
  author    = {Giuseppe Cuccu and
               Julian Togelius and
               Philippe Cudr{\'{e}}{-}Mauroux},
  title     = {Playing Atari with Six Neurons},
  journal   = {CoRR},
  volume    = {abs/1806.01363},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.01363},
  eprinttype = {arXiv},
  eprint    = {1806.01363},
  timestamp = {Mon, 13 Aug 2018 16:46:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-01363.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

@article{bucsoniu2018reinforcement,
  title={Reinforcement learning for control: Performance, stability, and deep approximators},
  author={Bu{\c{s}}oniu, Lucian and de Bruin, Tim and Toli{\'c}, Domagoj and Kober, Jens and Palunko, Ivana},
  journal={Annual Reviews in Control},
  volume={46},
  pages={8--28},
  year={2018},
  publisher={Elsevier}
}

@article{recht2018tour,
  title={A tour of reinforcement learning: The view from continuous control},
  author={Recht, Benjamin},
  journal={arXiv preprint arXiv:1806.09460},
  year={2018}
}

@phdthesis{wierstra2010study,
  title={A Study in Direct Policy Search},
  author={Wierstra, Daniel},
  year={2010},
  school={Technische Universit{\"a}t M{\"u}nchen}
}

@inproceedings{el2005direct,
  title={Direct Policy Search Reinforcement Learning for Robot Control.},
  author={El-Fakdi, Andres and Carreras, Marc and Palomeras, Narc{\'\i}s},
  booktitle={CCIA},
  pages={9--16},
  year={2005}
}

@article{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan and others},
  journal={Foundations and Trends{\textregistered} in Robotics},
  volume={2},
  number={1--2},
  pages={1--142},
  year={2013},
  publisher={Now Publishers, Inc.}
}

@article{ha2017visual,
  title   = "A Visual Guide to Evolution Strategies",
  author  = "Ha, David",
  journal = "blog.otoro.net",
  year    = "2017",
  url     = "https://blog.otoro.net/2017/10/29/visual-evolution-strategies/"
}

@article{wu2008top,
  title={Top 10 algorithms in data mining},
  author={Wu, Xindong and Kumar, Vipin and Ross Quinlan, J and Ghosh, Joydeep and Yang, Qiang and Motoda, Hiroshi and McLachlan, Geoffrey J and Ng, Angus and Liu, Bing and Yu, Philip S and others},
  journal={Knowledge and information systems},
  volume={14},
  number={1},
  pages={1--37},
  year={2008},
  publisher={Springer}
}

@book{quinlan2014c4,
  title={C4. 5: programs for machine learning},
  author={Quinlan, J Ross},
  year={2014},
  publisher={Elsevier}
}

@book{breiman2017classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
  year={2017},
  publisher={Routledge}
}

@article{yang2018deep,
  title={Deep neural decision trees},
  author={Yang, Yongxin and Morillo, Irene Garcia and Hospedales, Timothy M},
  journal={arXiv preprint arXiv:1806.06988},
  year={2018}
}

@inproceedings{silva2020optimization,
  title={Optimization methods for interpretable differentiable decision trees applied to reinforcement learning},
  author={Silva, Andrew and Gombolay, Matthew and Killian, Taylor and Jimenez, Ivan and Son, Sung-Hyun},
  booktitle={International conference on artificial intelligence and statistics},
  pages={1855--1865},
  year={2020},
  organization={PMLR}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{rosenblatt1958perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}

@book{dong2020deep,
  title={Deep Reinforcement Learning},
  author={Dong, Hao and Dong, Hao and Ding, Zihan and Zhang, Shanghang and Chang},
  year={2020},
  publisher={Springer}
}
