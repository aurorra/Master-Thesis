% !TEX root = ../main.tex

\chapter{Conclusion}
\label{ch:conclusions}

This work's driving question was whether we could find alternative models for direct policy search whose performance is comparable to neural networks, which were already successfully applied as policy approximators in neuroevolution. To investigate how these models compare to neural networks and what advantages they have, two research questions were introduced in Section~\ref{sec:research_questions}. In addition, one research question was formulated concerning the architecture of a model for additional analysis.

\paragraph*{RQ1: How do function approximators other than neural networks compare with the latter?} I directly compared the alternative models, the polynomial and binary tree models, to neural networks. The polynomial model produced results comparable to those of neural networks. For the environment \verb|CartPole|, it delivered a more desirable score distribution for polynomials of degrees two and three. We would still prefer neural networks to tackle the problem of the \verb|Acrobot| environment. The environment \verb|MountainCar| seems to produce the same score distribution regardless of the model used. We cannot conclude that using the polynomial model robustly produces better results or results comparable to neural networks.

The binary tree model could deliver comparable results and even outperformed neural networks several times. The simplicity of the model did not limit the model's performance. The opposite is the case. It significantly outperformed neural networks for the environment \verb|CartPole|. Since \verb|CartPole| represents a relatively simple problem, the simple structure of binary trees is advantageous compared to the complex architecture of neural networks. Neural networks have proven that they are capable of solving many challenging problems. Finding a good strategy with neural networks seems less efficient for a more straightforward task.

The search space of the model can explain these results. A more complex model like neural networks with multiple hidden layers has a much larger search space in which they search for a good strategy for a given task. A large search space is a disadvantage when the task is easier to solve. We must carefully select our approach and adapt to the complexity of the task we want to solve.

The environment \verb|MountainCar| again produces a similar score distribution. The mean values seem to be identical. There are a few higher individual scores for the binary tree model. As it comes from the construction of the environment, the problem implemented in \verb|MountainCar| is hard to solve by RWG. All of the tested models showed similar findings. The large fitness plateau remains for all of them. as it comes from the construction of the environment. To solve the problem, we need a learning algorithm high in exploration. For this use case, techniques in black-box optimization offer a good framework. Training a model with a learning algorithm prone to getting stuck in a local optimum will likely not result in a robust model that can solve the task. Also for the environment \verb|Acrobot|, the results of the two models look very similar. Although there are a few differences, both models seem equally suited to solve this task with the proper learning technique. Since a fitness plateau is present, an explorative learning algorithm should produce the best results.

Although the binary tree model only outputs discrete actions that are fixed, the results for the environment \verb|Pendulum| can compare to those of neural networks. Both models seem to be suited to solve the task reliably with an appropriate learning algorithm. In this case, the danger of being stuck in a local optimum is less prevalent than for the environment \verb|Acrobot|. Thus, the learning algorithm does not have to be as explorative.

The environment \verb|MountainCarContiuous| delivered counterintuitive results. The restriction of the binary tree model to only output the two actions -1 and 1 from the otherwise continuous action space negatively influenced the model's performance. Changing the actions from -1 and 1 to 0 and 1 resulted in a significantly better score distribution. Since the action defines the directional force applied to the car, a value between 0 and 1 means that we apply no force at all or actively push the car to the right in the direction of the target. Thus, the results show that the model does not necessarily have to learn to accelerate the car to the left and right to solve the task.

To conclude these findings, the binary tree model looks promising for direct policy search problems in reinforcement learning. Combined with a suited learning technique, it should robustly produce results comparable to those of neural networks.

\paragraph*{RQ2: What advantages and disadvantages can we see with other function approximators?} With neural networks, we have many hyperparameters that need fine-tuning. Hyperparameters such as the activation function, number of hidden layers and neurons influence the network structure significantly. Parameters such as the learning rate, number of epochs, and batch size, on the other hand, influence the training of the network. For both the polynomial model and the binary tree model, we have only one parameter, namely the degree of the polynomial and the number of nodes of the binary tree. Thus, finding a suitable configuration of the architecture of the alternative is straightforward and does not need much effort as opposed to neural network models. In addition, the binary tree model offers much more insight into decision-making than the neural network model. To comprehend how a neural network makes a decision is very hard. The binary tree model offers much more interpretability in that sense.

\paragraph{RQ3: How does the bias influence the performance of the model?} Adding bias had a negative impact on all discrete models for the polynomial model and on almost all five classic control environments for the neural network model. In my experiments with the number of weights, the number of layers, and the number of neurons, none of these changes influenced the model's performance as much as the bias did. There seems to be something specific about the use of bias that changes the performance for these environments in the setting of RWG. Why this is the case needs further research. However, there are two exceptions. The environment \verb|MountainCarContiuous| was very reactive to each change in the architecture or the number of weights. The environment \verb|Pendulum| did not show a significant difference when using bias vs. when not using bias. A change in the architecture or the number of weights affected it similarly.


\section{Future Work}
There is much further research that can be done in this area. This work represents the first step in the direction of alternative models like the binary tree model. This thesis showed that the binary tree model looks promising and can produce results comparable to neural networks while maintaining a simple architecture and interpretability. However, it would be interesting how we can adapt the model to work better on specific problems. The current implementation of the model can undoubtedly be improved. For continuous action spaces, we can adapt the leaf nodes to be included in the learning algorithm or implement a function instead of outputting a fixed action.

So far, no practical learning technique has been involved. It would be interesting to see how the model performs with state-of-the-art continuous black-box optimization optimizers such as CMA-ES replacing RWG. Additionally, the model should be tested in more challenging benchmark problems like the environment \verb|BipedalWalker| also included in the set of environments provided by the OpenAI Gym interface.

Finally, it would be interesting to see how other models perform in this setting. With techniques in black-box optimization, there are numerous possibilities.
