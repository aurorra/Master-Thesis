% !TEX root = ../main.tex

Neural networks as generic function approximators can solve many challenging problems. Regardless, they can only be applied successfully for a suited problem structure. A large part of the success of neural networks can be attributed to the efficiency of backpropagation which requires estimating accurate gradients. However, there are many areas where calculating an accurate gradient is non-trivial, including problems in reinforcement learning. In contrast, black-box optimization techniques are less limiting. They presume no constraints on the problem structure, the model, or the solution. With this flexibility, we can study alternative models to neural networks that are yet unexplored in the context of reinforcement learning. This thesis aims to achieve comparable with a function approximator other than neural networks. To this end, I analyzed the performance of polynomial and binary tree models on reinforcement learning benchmark problems. I compared these results to those of neural networks. In the experiments, I used random weight guessing to analyze the models. The results show that the binary tree model can produce results comparable to neural networks and even outperforms them while providing essential advantages. The simple structure of the binary tree model makes hyperparameter tuning straightforward and provides high interpretability.
