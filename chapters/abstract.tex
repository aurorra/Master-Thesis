% !TEX root = ../main.tex

Neural networks as generic function approximators can solve many challenging problems. Regardless, they can only be applied successfully for a suited problem structure. A large part of the success of neural networks can be attributed to the efficiency of the backpropagation algorithm, which requires labeled data to estimate accurate error gradients. However, there are many areas where accessing labeled data is non-trivial, including problems in reinforcement learning. In contrast, black-box optimization techniques are less limiting and can be used to optimize the parameters of any function approximator. They presume no constraints on the problem structure, the model, or the solution. With this flexibility, we can study alternative models to neural networks that are yet unexplored in the context of reinforcement learning. This thesis aims to achieve comparable results with a function approximator other than neural networks. To this end, I analyzed the performance of polynomial and binary tree models on reinforcement learning benchmark problems. I compared these results to those of neural networks. The results show that the binary tree model can produce results comparable to neural networks, and even outperforms them, while providing essential advantages. The simple structure of the binary tree model makes hyperparameter tuning straightforward and provides high interpretability.
